# m&ms
m&ms is a benchmark for evaluating large language model (LLM) agents' tool-use abilities on multi-step multi-modal tasks. You can find the evaluation dataset on [HuggingFace](https://huggingface.co/datasets/zixianma/mms).

## Dataset examples


## Dataset details
This dataset contains 4K+ multi-step multi-modal tasks involving 33 tools that include 13 multi-modal models, 9 (free) public APIs, and 11 image processing modules. For each of these task queries, we provide automatically generated plans using this realistic toolset. We further provide a high-quality subset of 1,565 human-verified task plans and 882 human-verified, filtered, and correctly executable plans.

## Dataset generation

## Evaluation
Code coming soon!

## Citation
TODO
